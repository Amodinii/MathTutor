{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e80a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec4824f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Codes\\RAG Models\\Math Tutor\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_21360\\4032688704.py:8: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from Tutor.Services.ReasoningModel import ReasoningModel\n"
     ]
    }
   ],
   "source": [
    "from Tutor.Tools.OCRModel import OCRModel\n",
    "from Tutor.Tools.WebSearch import WebSearch\n",
    "from Tutor.Services.InputHandler import InputHandler\n",
    "from Tutor.Services.Routing import Routing\n",
    "from Tutor.Services.EmbeddingModel import EmbeddingModel\n",
    "from Tutor.Services.VectorStore import VectorStore\n",
    "from Tutor.Data.PushToDB import PushToDB\n",
    "from Tutor.Services.ReasoningModel import ReasoningModel\n",
    "from Tutor.Services.TeachingModel import TeachingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d15b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from typing import TypedDict\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4bf8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = \"params.yaml\"\n",
    "with open (yaml_path) as yaml_file:\n",
    "    content = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce69248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       " 'reasoning': {'name': 'llama-3.3-70b-versatile', 'task': 'Reasoning'},\n",
       " 'teaching_model': {'name': 'deepseek-r1-distill-llama-70b',\n",
       "  'task': 'Question Answering'},\n",
       " 'vectorstore': {'num_results': 5, 'similarity_threshold': 0.5},\n",
       " 'data': {'folder_name': 'Tutor/Data/Math/'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e2095e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tutor/Data/Math/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = content['data']['folder_name']\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb074d95",
   "metadata": {},
   "source": [
    "### Testing our Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d53c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"This is a sample query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf8ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"This is sentence 1\",\n",
    "    \"This is sentence 2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c81cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-11 09:55:09,164] - 24 logger - INFO - EmbeddingModel: - Embedding model 'sentence-transformers/all-MiniLM-L6-v2' initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = EmbeddingModel(model_name = content['embedding_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fbbc867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-11 09:55:09,704] - 36 logger - INFO - EmbeddingModel: - Embedding text: This is a sample query...\n",
      "[2025-05-11 09:55:10,174] - 40 logger - ERROR - EmbeddingModel: - Embedding error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "ename": "TutorException",
     "evalue": "Error occurred while running the python script, in file [d:\\Codes\\RAG Models\\Math Tutor\\Tutor\\Services\\EmbeddingModel.py], line [37]. \nError Message: [Expecting value: line 1 column 1 (char 0)]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Codes\\RAG Models\\Math Tutor\\venv\\Lib\\site-packages\\requests\\models.py:974\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m974\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    976\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    977\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:338\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    336\u001b[39m \n\u001b[32m    337\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:356\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Codes\\RAG Models\\Math Tutor\\Tutor\\Services\\EmbeddingModel.py:37\u001b[39m, in \u001b[36mEmbeddingModel.embed_query\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     36\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbedding text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext[:\u001b[32m30\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Codes\\RAG Models\\Math Tutor\\venv\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:483\u001b[39m, in \u001b[36mHuggingFaceInferenceAPIEmbeddings.embed_query\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute query embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    476\u001b[39m \n\u001b[32m    477\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    481\u001b[39m \u001b[33;03m    Embeddings for the text.\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Codes\\RAG Models\\Math Tutor\\venv\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:472\u001b[39m, in \u001b[36mHuggingFaceInferenceAPIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    464\u001b[39m response = requests.post(\n\u001b[32m    465\u001b[39m     \u001b[38;5;28mself\u001b[39m._api_url,\n\u001b[32m    466\u001b[39m     headers=\u001b[38;5;28mself\u001b[39m._headers,\n\u001b[32m   (...)\u001b[39m\u001b[32m    470\u001b[39m     },\n\u001b[32m    471\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Codes\\RAG Models\\Math Tutor\\venv\\Lib\\site-packages\\requests\\models.py:978\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    976\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    977\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTutorException\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43membedding_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m[:\u001b[32m5\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Codes\\RAG Models\\Math Tutor\\Tutor\\Services\\EmbeddingModel.py:41\u001b[39m, in \u001b[36mEmbeddingModel.embed_query\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[32m     40\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbedding error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mve\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TutorException(ve, sys)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     43\u001b[39m     logger.error(\u001b[33m\"\u001b[39m\u001b[33mError embedding text...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTutorException\u001b[39m: Error occurred while running the python script, in file [d:\\Codes\\RAG Models\\Math Tutor\\Tutor\\Services\\EmbeddingModel.py], line [37]. \nError Message: [Expecting value: line 1 column 1 (char 0)]"
     ]
    }
   ],
   "source": [
    "print(embedding_model.embed_query(text=query)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84310dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding_model.embed_documents(texts=documents)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5937cf",
   "metadata": {},
   "source": [
    "The embedding model is working properly, without any errors, for both the text and the documents.<br>\n",
    "Only thing to remember is that our embeddings model is accessed via API, hence a stable internet connection is required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b709ef",
   "metadata": {},
   "source": [
    "### Test the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f81317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = VectorStore(model_name = content['embedding_model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66e873d",
   "metadata": {},
   "source": [
    " Checking if we can add data into our vector DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"IPL is going on and RCB is the team at the first position\",\n",
    "    \"There has been a huge attack on the man living the next door\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will create a document object\n",
    "document_objects = [Document(page_content=doc, metadata={\"source\": \"example\"}) for doc in documents]\n",
    "\n",
    "# Then we will add the documents to the vector store\n",
    "vector_store.add_documents(document_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34530de2",
   "metadata": {},
   "source": [
    "Data is being added successfully into our vector database, the only thing we have to ensure is that, it is a Document Object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3265fd4",
   "metadata": {},
   "source": [
    "Check if we are able to retrieve data from the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a81f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.retrieve(query=\"RCB\", threshold=content['vectorstore']['similarity_threshold'], num_results=content['vectorstore']['num_results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0408deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32d1c01",
   "metadata": {},
   "source": [
    "We can see that the retrieving of the data is also happening successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30546b0a",
   "metadata": {},
   "source": [
    "This means that our vector store is working properly and successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee22c7",
   "metadata": {},
   "source": [
    "### Testing the web search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda48a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can you calculate the differential of x^2+3x+2 at x=2?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db28d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search_tool(query):\n",
    "    \"\"\"Tool to perform a web search.\"\"\"\n",
    "    web_search = WebSearch(max_results=content['vectorstore']['num_results'])\n",
    "    results = web_search.search(query)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = web_search_tool(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_tool(\"How many 4 digit numbers can be made with 1,2,3,4,5,6,7,8,9 such that no two consecutive digits are same?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1618480",
   "metadata": {},
   "source": [
    "We can see that our web search tool is working, and it is returning a dictionary. The main things is the url,  from which we can scrape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdbb0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    response['results'][0]['url']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd79ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc121617",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1af4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_tool(image):\n",
    "    \"\"\"Tool to perform OCR on an image.\"\"\"\n",
    "    ocr_model = OCRModel()\n",
    "    text = ocr_model.get_text(image)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a199dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = VectorStore(model_name = content['embedding_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22981608",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_handler = InputHandler()\n",
    "routing = Routing(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fac025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: list\n",
    "    input_type: ['Text', 'Image', None]\n",
    "    route_type: ['Found in DB', 'Not Found in DB', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c99b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(state: State) -> State:\n",
    "    \"\"\"Generate a response based on input type and possible OCR results.\"\"\"\n",
    "    input_type = state[\"input_type\"]\n",
    "    ocr_result = state.get(\"ocr_result\")\n",
    "    \n",
    "    if input_type == \"text\":\n",
    "        response = \"I detected your input as text. Processing directly.\"\n",
    "    elif input_type == \"image\" and ocr_result:\n",
    "        response = f\"I detected your input as an image. OCR extracted the following text: {ocr_result}\"\n",
    "    else:\n",
    "        response = \"I couldn't properly process your input.\"\n",
    "    \n",
    "    return {\"messages\": state[\"messages\"] + [AIMessage(content=response)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e52f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dff3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First node is the node to identify the input type\n",
    "graph_builder.add_node(\n",
    "    \"DetectInputType\", input_handler.check_input_type\n",
    ")\n",
    "\n",
    "# Next node is the OCR model, which will be the tool\n",
    "graph_builder.add_node(\n",
    "    \"ocr_tool\", ocr_tool\n",
    ")\n",
    "\n",
    "# Router Node\n",
    "graph_builder.add_node(\n",
    "    \"router-node\", routing.route\n",
    ")\n",
    "\n",
    "graph_builder.add_node(\n",
    "    \"web_search_tool\", web_search_tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cdeb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_conditional_edges(\n",
    "        \"DetectInputType\",\n",
    "        lambda state: state[\"input_type\"],\n",
    "        {\n",
    "            \"text\": \"router-node\",  # If text, go directly to response\n",
    "            \"image\": \"ocr_tool\",          # If image, go to OCR first\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect OCR to response generation\n",
    "graph_builder.add_edge(\"ocr_tool\", \"router-node\")\n",
    "    \n",
    "# Set the final node to END\n",
    "graph_builder.add_conditional_edges(\n",
    "        \"router-node\",\n",
    "        lambda state: state[\"route_type\"],\n",
    "        {\n",
    "            \"Found in DB\": END,\n",
    "            \"Not Found in DB\": \"web_search_tool\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "graph_builder.add_edge(\"web_search_tool\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284add0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.set_entry_point(\"DetectInputType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc22373",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e370b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b9e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
